{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class PorterRussian:\n",
    "    PERFECTIVEGROUND =  re.compile(u\"((ив|ивши|ившись|ыв|ывши|ывшись)|((?<=[ая])(в|вши|вшись)))$\")\n",
    "    REFLEXIVE = re.compile(u\"(с[яь])$\")\n",
    "    ADJECTIVE = re.compile(u\"(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$\")\n",
    "    PARTICIPLE = re.compile(u\"((ивш|ывш|ующ)|((?<=[ая])(ем|нн|вш|ющ|щ)))$\")\n",
    "    VERB = re.compile(u\"((ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю)|((?<=[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)))$\")\n",
    "    NOUN = re.compile(u\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\")\n",
    "    RVRE = re.compile(u\"^(.*?[аеиоуыэюя])(.*)$\")\n",
    "    DERIVATIONAL = re.compile(u\".*[^аеиоуыэюя]+[аеиоуыэюя].*ость?$\")\n",
    "    DER = re.compile(u\"ость?$\")\n",
    "    SUPERLATIVE = re.compile(u\"(ейше|ейш)$\")\n",
    "    I = re.compile(u\"и$\")\n",
    "    P = re.compile(u\"ь$\")\n",
    "    NN = re.compile(u\"нн$\")\n",
    "\n",
    "    def stem(word):\n",
    "        word = word.lower()\n",
    "        word = word.replace(u'ё', u'е')\n",
    "        m = re.match(PorterRussian.RVRE, word)\n",
    "        if m and m.groups():\n",
    "            pre = m.group(1)\n",
    "            rv = m.group(2)\n",
    "            temp = PorterRussian.PERFECTIVEGROUND.sub('', rv, 1)\n",
    "            if temp == rv:\n",
    "                rv = PorterRussian.REFLEXIVE.sub('', rv, 1)\n",
    "                temp = PorterRussian.ADJECTIVE.sub('', rv, 1)\n",
    "                if temp != rv:\n",
    "                    rv = temp\n",
    "                    rv = PorterRussian.PARTICIPLE.sub('', rv, 1)\n",
    "                else:\n",
    "                    temp = PorterRussian.VERB.sub('', rv, 1)\n",
    "                    if temp == rv:\n",
    "                        rv = PorterRussian.NOUN.sub('', rv, 1)\n",
    "                    else:\n",
    "                        rv = temp\n",
    "            else:\n",
    "                rv = temp\n",
    "            \n",
    "            rv = PorterRussian.I.sub('', rv, 1)\n",
    "\n",
    "            if re.match(PorterRussian.DERIVATIONAL, rv):\n",
    "                rv = PorterRussian.DER.sub('', rv, 1)\n",
    "\n",
    "            temp = PorterRussian.P.sub('', rv, 1)\n",
    "            if temp == rv:\n",
    "                rv = PorterRussian.SUPERLATIVE.sub('', rv, 1)\n",
    "                rv = PorterRussian.NN.sub(u'н', rv, 1)\n",
    "            else:\n",
    "                rv = temp\n",
    "            word = pre+rv\n",
    "        return word\n",
    "    stem=staticmethod(stem)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class Solution:\n",
    "    \n",
    "    def __init__(self, C=2000, tfidf=True, train_titles=True, titles_significance = 0.2):\n",
    "        self.tfidf = tfidf\n",
    "        self.C = C\n",
    "        self.train_titles = train_titles\n",
    "        self.titles_significance = titles_significance\n",
    "        \n",
    "        self.labels = ['Вредоносное ПО', 'Инцидент', 'Прочее', 'Угроза', 'Уязвимость', 'Эксплойт'];\n",
    "        self.PorterEnglish = PorterStemmer()\n",
    "        self.PorterRussian = PorterRussian()\n",
    "        \n",
    "        self.word_position_en = {}\n",
    "        self.word_position_ru = {}\n",
    "        \n",
    "        self.word_position_en_titles = {}\n",
    "        self.word_position_ru_titles = {}\n",
    "        \n",
    "    def stem(self, word):\n",
    "        if re.search(r'[а-яА-ЯёЁ]', word):\n",
    "            return self.PorterRussian.stem(word)\n",
    "        else:\n",
    "            return self.PorterEnglish.stem(word)\n",
    "        \n",
    "    def get_lang(self, text):\n",
    "        if re.search(r'[а-яА-ЯёЁ]', text):\n",
    "            return 'russian'\n",
    "        else:\n",
    "            return 'english'\n",
    "    \n",
    "    def make_matrix(self, texts, lang, mode='train', for_titles=False):\n",
    "        indptr = [0]\n",
    "        column_indices = []\n",
    "        values = []\n",
    "        \n",
    "        if for_titles:\n",
    "            if lang == 'english':\n",
    "                word_position = self.word_position_en_titles\n",
    "            else:\n",
    "                word_position = self.word_position_ru_titles\n",
    "        else:\n",
    "            if lang == 'english':\n",
    "                word_position = self.word_position_en\n",
    "            else:\n",
    "                word_position = self.word_position_ru\n",
    "                \n",
    "        if mode == 'train':\n",
    "            for text in texts:\n",
    "                for word in text:\n",
    "                    index = word_position.setdefault(word, len(word_position))\n",
    "                    column_indices.append(index)\n",
    "                    values.append(1)\n",
    "                indptr.append(len(column_indices))\n",
    "        else:\n",
    "            for text in texts:\n",
    "                for word in text:\n",
    "                    if word in word_position:\n",
    "                        index = word_position[word]\n",
    "                        column_indices.append(index)\n",
    "                        values.append(1)\n",
    "                    \n",
    "                    index = len(word_position) - 1\n",
    "                    column_indices.append(index)\n",
    "                    values.append(0)\n",
    "                    \n",
    "                indptr.append(len(column_indices))\n",
    "            \n",
    "        M = csr_matrix((values, column_indices, indptr), dtype=int)\n",
    "        \n",
    "        if self.tfidf:\n",
    "            trans = TfidfTransformer()\n",
    "            trans.fit(M)\n",
    "            M = trans.transform(M)\n",
    "        return M\n",
    "\n",
    "    def get_answers(self, train_corpus):\n",
    "        answers = []\n",
    "        for obj in train_corpus:\n",
    "            all_users_labels = []\n",
    "            for user in obj[2]:\n",
    "                all_users_labels += list(obj[2][user])\n",
    "            \n",
    "            count = Counter(all_users_labels)\n",
    "        \n",
    "#             max_count = max(count.values())\n",
    "#             candidates = [label for label in count.keys() if count[label] == max_count]\n",
    "#             answers.append(random.choice(candidates))\n",
    "            answers.append(count.most_common(1)[0][0])\n",
    "        return np.array(answers)\n",
    "    \n",
    "    def train(self, train_corpus):\n",
    "        texts = np.array([list(map(lambda word : self.stem(word), nltk.word_tokenize(re.sub(r'\\W', ' ', obj[1].lower())))) for obj in train_corpus])\n",
    "        texts_langs = np.array([self.get_lang(obj[1]) for obj in train_corpus])\n",
    "        \n",
    "        answers = self.get_answers(train_corpus)\n",
    "        \n",
    "        M_en = self.make_matrix(texts[texts_langs=='english'], 'english')\n",
    "        M_ru = self.make_matrix(texts[texts_langs=='russian'], 'russian')\n",
    "        \n",
    "        self.en_clf = LogisticRegression(max_iter=10000, C=self.C)\n",
    "        self.en_clf.fit(M_en, answers[texts_langs=='english'])\n",
    "        \n",
    "        self.ru_clf = LogisticRegression(max_iter=10000, C=self.C)\n",
    "        self.ru_clf.fit(M_ru, answers[texts_langs=='russian'])\n",
    "    \n",
    "        \n",
    "        if self.train_titles:\n",
    "            titles = np.array([list(map(lambda word : self.stem(word), nltk.word_tokenize(re.sub(r'\\W', ' ', obj[0].lower())))) for obj in train_corpus])\n",
    "            titles_langs = np.array([self.get_lang(obj[0]) for obj in train_corpus])\n",
    "            \n",
    "            M_en = self.make_matrix(titles[titles_langs=='english'], 'english', for_titles = True)\n",
    "            M_ru = self.make_matrix(titles[titles_langs=='russian'], 'russian', for_titles = True)\n",
    "            \n",
    "            self.en_clf_titles = LogisticRegression(max_iter=10000, C=self.C)\n",
    "            self.en_clf_titles.fit(M_en, answers[titles_langs=='english'])\n",
    "            \n",
    "            self.ru_clf_titles = LogisticRegression(max_iter=10000, C=self.C)\n",
    "            self.ru_clf_titles.fit(M_ru, answers[titles_langs=='russian'])\n",
    "    \n",
    "        \n",
    "    def predict(self, news):\n",
    "        texts = np.array([list(map(lambda word : self.stem(word), nltk.word_tokenize(re.sub(r'\\W', ' ', obj[1].lower())))) for obj in news])\n",
    "        texts_langs = np.array([self.get_lang(obj[1]) for obj in news])\n",
    "        texts_probas = np.array([[None, None, None, None, None, None] for obj in news])\n",
    "        \n",
    "        en_indices = [i for i in range(len(texts_langs)) if texts_langs[i] == 'english']\n",
    "        ru_indices = [i for i in range(len(texts_langs)) if texts_langs[i] == 'russian']\n",
    "         \n",
    "        if (texts_langs == 'english').max():\n",
    "            M_en = self.make_matrix(texts[texts_langs=='english'], 'english', mode='predict')\n",
    "            texts_probas[en_indices] = self.en_clf.predict_proba(M_en)\n",
    "        \n",
    "        if (texts_langs == 'russian').max():\n",
    "            M_ru = self.make_matrix(texts[texts_langs=='russian'], 'russian', mode='predict')\n",
    "            texts_probas[ru_indices] = self.ru_clf.predict_proba(M_ru)\n",
    "        \n",
    "        probas = texts_probas\n",
    "        \n",
    "        \n",
    "        if self.train_titles:\n",
    "            titles = np.array([list(map(lambda word : self.stem(word), nltk.word_tokenize(re.sub(r'\\W', ' ', obj[0].lower())))) for obj in news])\n",
    "            titles_langs = np.array([self.get_lang(obj[0]) for obj in news])\n",
    "            titles_probas = np.array([[None, None, None, None, None, None] for obj in news])\n",
    "            \n",
    "            en_indices = [i for i in range(len(titles_langs)) if titles_langs[i] == 'english']\n",
    "            ru_indices = [i for i in range(len(titles_langs)) if titles_langs[i] == 'russian']\n",
    "            \n",
    "            if (titles_langs == 'english').max():\n",
    "                M_en = self.make_matrix(titles[titles_langs=='english'], 'english', mode='predict', for_titles = True)\n",
    "                titles_probas[en_indices] = self.en_clf_titles.predict_proba(M_en)\n",
    "        \n",
    "            if (titles_langs == 'russian').max():\n",
    "                M_ru = self.make_matrix(titles[titles_langs=='russian'], 'russian', mode='predict', for_titles = True)\n",
    "                titles_probas[ru_indices] = self.ru_clf_titles.predict_proba(M_ru) \n",
    "            \n",
    "            \n",
    "            probas = (1 - self.titles_significance) * texts_probas + self.titles_significance * titles_probas\n",
    "            \n",
    "        answers_indices = np.argmax(probas, axis = 1)\n",
    "        answers = [set([self.labels[i]]) for i in answers_indices]\n",
    "        return answers\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"q.json\", \"r\", encoding = \"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "texts_df = pd.DataFrame(df.groupby('text'))\n",
    "\n",
    "texts_corpus = []\n",
    "for elem in texts_df.values:\n",
    "    text = elem[0]\n",
    "    title = elem[1]['title'].values[0]\n",
    "    user_labels = {}\n",
    "    i = 0\n",
    "    for labels in elem[1]['labels'].values:\n",
    "        user_labels[i] = set(labels)\n",
    "        i +=1\n",
    "    obj = tuple([title, text, user_labels])\n",
    "    texts_corpus.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Solution()\n",
    "clf.train(texts_corpus[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=clf.predict(texts_corpus[800:818])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Вредоносное ПО'},\n",
       " {'Угроза'},\n",
       " {'Угроза'},\n",
       " {'Вредоносное ПО'},\n",
       " {'Прочее'},\n",
       " {'Угроза'},\n",
       " {'Инцидент'},\n",
       " {'Угроза'},\n",
       " {'Угроза'},\n",
       " {'Угроза'},\n",
       " {'Вредоносное ПО'},\n",
       " {'Вредоносное ПО'},\n",
       " {'Уязвимость'},\n",
       " {'Вредоносное ПО'},\n",
       " {'Угроза'},\n",
       " {'Вредоносное ПО'},\n",
       " {'Вредоносное ПО'},\n",
       " {'Угроза'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
